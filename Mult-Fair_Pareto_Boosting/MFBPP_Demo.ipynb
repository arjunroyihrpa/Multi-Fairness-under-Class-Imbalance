{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Multi_Fair_Boosting import Multi_Fair as maximus\n",
    "from sklearn.model_selection import StratifiedShuffleSplit as ss\n",
    "from DataPreprocessing.my_utils import get_score,get_fairness,vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " def train_classifier1(X_train, X_test, y_train, y_test, sa_index, p_Group, base_learners,preference):\n",
    "    \n",
    "    classifier = maximus(n_estimators=base_learners, saIndex=sa_index, saValue=p_Group,preference=None,pareto=True)\n",
    "    \n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_probs = classifier.predict_proba(X_test)[:, 1]\n",
    "    y_pred_labels = classifier.predict(X_test)\n",
    "    f=classifier.feature_importances_\n",
    "    #return classifier.conf_scores, classifier.get_weights_over_iterations(), classifier.get_initial_weights()\n",
    "    return y_pred_probs, y_pred_labels,classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X,y):\n",
    "    in_ts,pred1,fx=[],[],[]\n",
    "    sss = ss(n_splits=5,test_size=0.4)    \n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        in_ts.append(test_index)    \n",
    "        pb1,pd1,f1=train_classifier1(X_train, X_test, y_train, y_test, sa_index,     p_Group, 499,preference=None)\n",
    "        pred1.append(pd1)\n",
    "        fx.append(f1)\n",
    "        print(f1.theta-1,\" : \",f1.ob[f1.theta-1])\n",
    "    return in_ts,pred1,fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features we will be using for classification are: ['age_cat_25 - 45', 'age_cat_Greater than 45', 'age_cat_Less than 25', 'race', 'sex', 'priors_count', 'c_charge_degree', 'target'] \n",
      "\n",
      "105  :  [0.34491472 0.00834023 0.04984424]\n",
      "105  :  [0.33891346 0.01602889 0.08934119]\n",
      "495  :  [0.34523057 0.01388557 0.03871068]\n",
      "431  :  [0.33733418 0.06429419 0.03356974]\n",
      "79  :  [0.33765003 0.0567521  0.06377027]\n",
      "\n",
      "\n",
      "For Sensitive attribute index  4\n",
      "avg_TPR_unprot: 0.6580431410512911 avg_TPR_prot: 0.664430449451047\n",
      "avg_TNR_unprot: 0.6496822060638212 avg_TNR_prot: 0.6578987548714973\n",
      "avg_Maximum_Mistreatment: 0.05314702266867386\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "For Sensitive attribute index  3\n",
      "avg_TPR_unprot: 0.6322415561577047 avg_TPR_prot: 0.6728323795949164\n",
      "avg_TNR_unprot: 0.6405839546188818 avg_TNR_prot: 0.660952818932729\n",
      "avg_Maximum_Mistreatment: 0.05059890969283347\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Multi_Max_Mistreatment: 0.05314702266867386\n",
      "avg_TPR: 0.6591549295774647 avg_TNR: 0.6515205724508051\n",
      "avg_acc: 0.6551136363636363 avg_Bacc: 0.6553377510141349\n",
      "avg_auc: 0.6553377510141349\n"
     ]
    }
   ],
   "source": [
    "results,performance,Hx=[],[],[]\n",
    "for dt in ['Compas']:\n",
    "    if dt=='Adult':\n",
    "        from DataPreprocessing.load_adult import load_adult\n",
    "        X, y, sa_index, p_Group, x_control,F = load_adult()\n",
    "        #v='Adult_2_sensi_Mari_Sex'\n",
    "        saf=sa_index[1]\n",
    "    elif dt=='Bank':\n",
    "        from DataPreprocessing.load_bank import load_bank\n",
    "        X, y, sa_index, p_Group, x_control,F = load_bank()\n",
    "        saf=sa_index[0]\n",
    "        print(saf)\n",
    "    elif dt=='Credit':\n",
    "        from DataPreprocessing.load_credit import load_credit\n",
    "        X, y, sa_index, p_Group, x_control,F = load_credit()\n",
    "        saf=sa_index[0]\n",
    "    elif dt=='Compas':\n",
    "        from DataPreprocessing.load_compas_data import load_compas\n",
    "        X, y, sa, p_G, x_control,F = load_compas()\n",
    "        sa_index=[sa[-1],sa[0]]\n",
    "        p_Group=[p_G[-1],p_G[0]]\n",
    "    sensitives=[F[v] for v in sa_index]\n",
    "    in_ts,pred1,f1=train(X,y)\n",
    "    results.append(list(get_fairness(sa_index,p_Group,in_ts,pred1,X,y).values()))\n",
    "    performance.append(get_score(pred1,in_ts,X,y))\n",
    "    Hx.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
